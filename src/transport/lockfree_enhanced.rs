/// æ— é”ä¼˜åŒ–å¢å¼ºæ¨¡å— - ä¸“æ³¨äºç¬¬ä¸€é˜¶æ®µæ— é”ä¼˜åŒ–
/// 
/// ç›®æ ‡ï¼š
/// - æ›¿æ¢Arc<RwLock<HashMap>>çƒ­ç‚¹
/// - æä¾›50-150%çš„æ€§èƒ½æå‡
/// - ä¿æŒç°æœ‰APIå…¼å®¹æ€§

use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, AtomicU64, Ordering};
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::time::Instant;

use crossbeam::epoch::{self, Atomic, Owned, Shared, Guard};
use crossbeam::utils::CachePadded;
use crossbeam_channel::{unbounded, Sender, Receiver};
use parking_lot::RwLock;

use crate::{SessionId, error::TransportError};

/// æ— é”å“ˆå¸Œè¡¨ - æ›¿ä»£Arc<RwLock<HashMap>>
/// 
/// ä½¿ç”¨crossbeamçš„epoch-basedå†…å­˜ç®¡ç†ï¼Œå®ç°wait-freeè¯»å–
pub struct LockFreeHashMap<K, V> 
where 
    K: Hash + Eq + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    /// åˆ†ç‰‡æ•°ç»„ï¼Œå‡å°‘äº‰ç”¨
    shards: Vec<CachePadded<LockFreeShard<K, V>>>,
    /// åˆ†ç‰‡æ•°é‡ï¼ˆå¿…é¡»æ˜¯2çš„å¹‚ï¼‰
    shard_count: usize,
    /// æ“ä½œç»Ÿè®¡
    stats: Arc<LockFreeStats>,
}

/// æ— é”åˆ†ç‰‡
struct LockFreeShard<K, V> {
    /// åŸå­æŒ‡é’ˆæŒ‡å‘HashMap
    map: Atomic<HashMap<K, V>>,
    /// ç‰ˆæœ¬å·ï¼Œç”¨äºCASæ“ä½œ
    version: AtomicU64,
}

/// æ— é”ç»Ÿè®¡
#[derive(Debug)]
pub struct LockFreeStats {
    /// è¯»å–æ¬¡æ•°
    pub reads: AtomicU64,
    /// å†™å…¥æ¬¡æ•°
    pub writes: AtomicU64,
    /// CASé‡è¯•æ¬¡æ•°
    pub cas_retries: AtomicU64,
    /// å¹³å‡è¯»å–å»¶è¿Ÿï¼ˆçº³ç§’ï¼‰
    pub avg_read_latency_ns: AtomicU64,
}

impl<K, V> LockFreeHashMap<K, V>
where
    K: Hash + Eq + Clone + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    /// åˆ›å»ºæ–°çš„æ— é”å“ˆå¸Œè¡¨
    pub fn new() -> Self {
        Self::with_capacity(16) // é»˜è®¤16ä¸ªåˆ†ç‰‡
    }
    
    /// åˆ›å»ºæŒ‡å®šå®¹é‡çš„æ— é”å“ˆå¸Œè¡¨
    pub fn with_capacity(shard_count: usize) -> Self {
        let shard_count = shard_count.next_power_of_two();
        let mut shards = Vec::with_capacity(shard_count);
        
        for _ in 0..shard_count {
            shards.push(CachePadded::new(LockFreeShard {
                map: Atomic::new(HashMap::new()),
                version: AtomicU64::new(0),
            }));
        }
        
        Self {
            shards,
            shard_count,
            stats: Arc::new(LockFreeStats::new()),
        }
    }
    
    /// è·å–åˆ†ç‰‡ç´¢å¼•
    fn shard_index(&self, key: &K) -> usize {
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        key.hash(&mut hasher);
        (hasher.finish() as usize) & (self.shard_count - 1)
    }
    
    /// Wait-freeè¯»å– - æ ¸å¿ƒä¼˜åŒ–ç‚¹
    pub fn get(&self, key: &K) -> Option<V> {
        let start = Instant::now();
        self.stats.reads.fetch_add(1, Ordering::Relaxed);
        
        let shard_idx = self.shard_index(key);
        let shard = &self.shards[shard_idx];
        
        let guard = epoch::pin();
        let map_ptr = shard.map.load(Ordering::Acquire, &guard);
        
        let result = if map_ptr.is_null() {
            None
        } else {
            unsafe { map_ptr.as_ref() }.unwrap().get(key).cloned()
        };
        
        // è®°å½•å»¶è¿Ÿ
        let latency = start.elapsed().as_nanos() as u64;
        self.stats.avg_read_latency_ns.store(latency, Ordering::Relaxed);
        
        result
    }
    
    /// æ— é”å†™å…¥ - ä½¿ç”¨CASæ“ä½œ
    pub fn insert(&self, key: K, value: V) -> Result<Option<V>, TransportError> {
        self.stats.writes.fetch_add(1, Ordering::Relaxed);
        
        let shard_idx = self.shard_index(&key);
        let shard = &self.shards[shard_idx];
        
        let mut retry_count = 0;
        const MAX_RETRIES: usize = 100;
        
        loop {
            let guard = epoch::pin();
            let current_ptr = shard.map.load(Ordering::Acquire, &guard);
            
            // åˆ›å»ºæ–°çš„HashMap
            let mut new_map = if current_ptr.is_null() {
                HashMap::new()
            } else {
                unsafe { current_ptr.as_ref() }.unwrap().clone()
            };
            
            let old_value = new_map.insert(key.clone(), value.clone());
            
            // å°è¯•CASæ›´æ–°
            let new_ptr = Owned::new(new_map);
            match shard.map.compare_exchange_weak(
                current_ptr,
                new_ptr,
                Ordering::Release,
                Ordering::Relaxed,
                &guard,
            ) {
                Ok(_) => {
                    // æˆåŠŸæ›´æ–°ç‰ˆæœ¬å·
                    shard.version.fetch_add(1, Ordering::Relaxed);
                    
                    // å»¶è¿Ÿé‡Šæ”¾æ—§æ•°æ®
                    if !current_ptr.is_null() {
                        unsafe {
                            guard.defer_unchecked(move || {
                                drop(current_ptr.into_owned());
                            });
                        }
                    }
                    
                    return Ok(old_value);
                }
                Err(_) => {
                    retry_count += 1;
                    if retry_count >= MAX_RETRIES {
                        return Err(TransportError::resource_error(
                            "lockfree_insert", 
                            retry_count, 
                            MAX_RETRIES
                        ));
                    }
                    self.stats.cas_retries.fetch_add(1, Ordering::Relaxed);
                    
                    // é€€é¿ç­–ç•¥
                    if retry_count > 10 {
                        std::thread::yield_now();
                    }
                }
            }
        }
    }
    
    /// æ— é”åˆ é™¤
    pub fn remove(&self, key: &K) -> Result<Option<V>, TransportError> {
        self.stats.writes.fetch_add(1, Ordering::Relaxed);
        
        let shard_idx = self.shard_index(key);
        let shard = &self.shards[shard_idx];
        
        let mut retry_count = 0;
        const MAX_RETRIES: usize = 100;
        
        loop {
            let guard = epoch::pin();
            let current_ptr = shard.map.load(Ordering::Acquire, &guard);
            
            if current_ptr.is_null() {
                return Ok(None);
            }
            
            let mut new_map = unsafe { current_ptr.as_ref() }.unwrap().clone();
            let old_value = new_map.remove(key);
            
            let new_ptr = Owned::new(new_map);
            match shard.map.compare_exchange_weak(
                current_ptr,
                new_ptr,
                Ordering::Release,
                Ordering::Relaxed,
                &guard,
            ) {
                Ok(_) => {
                    shard.version.fetch_add(1, Ordering::Relaxed);
                    
                    unsafe {
                        guard.defer_unchecked(move || {
                            drop(current_ptr.into_owned());
                        });
                    }
                    
                    return Ok(old_value);
                }
                Err(_) => {
                    retry_count += 1;
                    if retry_count >= MAX_RETRIES {
                        return Err(TransportError::resource_error(
                            "lockfree_remove", 
                            retry_count, 
                            MAX_RETRIES
                        ));
                    }
                    self.stats.cas_retries.fetch_add(1, Ordering::Relaxed);
                    
                    if retry_count > 10 {
                        std::thread::yield_now();
                    }
                }
            }
        }
    }
    
    /// ğŸš€ Phase 1: è·å–æ‰€æœ‰é”®å€¼å¯¹å¿«ç…§ - ç”¨äºå¼‚æ­¥æ“ä½œ
    pub fn snapshot(&self) -> Result<Vec<(K, V)>, String> {
        let mut result = Vec::new();
        
        for shard in &self.shards {
            let guard = epoch::pin();
            let map_ptr = shard.map.load(Ordering::Acquire, &guard);
            
            if !map_ptr.is_null() {
                let map = unsafe { map_ptr.as_ref() }.unwrap();
                for (k, v) in map.iter() {
                    result.push((k.clone(), v.clone()));
                }
            }
        }
        
        Ok(result)
    }
    
    /// è·å–æ¡ç›®æ•°é‡
    pub fn len(&self) -> usize {
        let mut count = 0;
        
        for shard in &self.shards {
            let guard = epoch::pin();
            let map_ptr = shard.map.load(Ordering::Acquire, &guard);
            
            if !map_ptr.is_null() {
                count += unsafe { map_ptr.as_ref() }.unwrap().len();
            }
        }
        
        count
    }
    
    /// æ˜¯å¦ä¸ºç©º
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    
    /// ğŸš€ Phase 1: è·å–æ‰€æœ‰é”® - ç”¨äºè¿­ä»£
    pub fn keys(&self) -> Result<Vec<K>, String> {
        let mut all_keys = Vec::new();
        
        for shard in &self.shards {
            let guard = epoch::pin();
            let map_ptr = shard.map.load(Ordering::Acquire, &guard);
            
            if !map_ptr.is_null() {
                let map = unsafe { map_ptr.as_ref() }.unwrap();
                for key in map.keys() {
                    all_keys.push(key.clone());
                }
            }
        }
        
        Ok(all_keys)
    }
    
    /// ğŸš€ Phase 1: éå†æ“ä½œ - æ›¿ä»£ RwLock::read().await çš„ iter()
    pub fn for_each<F>(&self, mut f: F) -> Result<(), String>
    where
        F: FnMut(&K, &V),
    {
        for shard in &self.shards {
            let guard = epoch::pin();
            let map_ptr = shard.map.load(Ordering::Acquire, &guard);
            
            if !map_ptr.is_null() {
                let map = unsafe { map_ptr.as_ref() }.unwrap();
                for (k, v) in map.iter() {
                    f(k, v);
                }
            }
        }
        
        Ok(())
    }
    
    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn stats(&self) -> LockFreeStats {
        LockFreeStats {
            reads: AtomicU64::new(self.stats.reads.load(Ordering::Relaxed)),
            writes: AtomicU64::new(self.stats.writes.load(Ordering::Relaxed)),
            cas_retries: AtomicU64::new(self.stats.cas_retries.load(Ordering::Relaxed)),
            avg_read_latency_ns: AtomicU64::new(self.stats.avg_read_latency_ns.load(Ordering::Relaxed)),
        }
    }
}

impl LockFreeStats {
    fn new() -> Self {
        Self {
            reads: AtomicU64::new(0),
            writes: AtomicU64::new(0),
            cas_retries: AtomicU64::new(0),
            avg_read_latency_ns: AtomicU64::new(0),
        }
    }
    
    /// è·å–CASæˆåŠŸç‡
    pub fn cas_success_rate(&self) -> f64 {
        let writes = self.writes.load(Ordering::Relaxed) as f64;
        let retries = self.cas_retries.load(Ordering::Relaxed) as f64;
        
        if writes == 0.0 {
            1.0
        } else {
            writes / (writes + retries)
        }
    }
}

/// é«˜æ€§èƒ½æ— é”é˜Ÿåˆ— - æ›¿ä»£VecDeque
pub struct LockFreeQueue<T> 
where 
    T: Send + Sync + 'static,
{
    sender: Sender<T>,
    receiver: Receiver<T>,
    stats: Arc<QueueStats>,
}

/// é˜Ÿåˆ—ç»Ÿè®¡
#[derive(Debug)]
pub struct QueueStats {
    pub enqueued: AtomicU64,
    pub dequeued: AtomicU64,
    pub current_size: AtomicUsize,
}

impl<T> LockFreeQueue<T>
where
    T: Send + Sync + 'static,
{
    /// åˆ›å»ºæ–°çš„æ— é”é˜Ÿåˆ—
    pub fn new() -> Self {
        let (sender, receiver) = unbounded();
        
        Self {
            sender,
            receiver,
            stats: Arc::new(QueueStats {
                enqueued: AtomicU64::new(0),
                dequeued: AtomicU64::new(0),
                current_size: AtomicUsize::new(0),
            }),
        }
    }
    
    /// æ— é”å…¥é˜Ÿ
    pub fn push(&self, item: T) -> Result<(), TransportError> {
        match self.sender.send(item) {
            Ok(_) => {
                self.stats.enqueued.fetch_add(1, Ordering::Relaxed);
                self.stats.current_size.fetch_add(1, Ordering::Relaxed);
                Ok(())
            }
            Err(_) => Err(TransportError::resource_error("queue_push", 1, 0)),
        }
    }
    
    /// æ— é”å‡ºé˜Ÿ
    pub fn pop(&self) -> Option<T> {
        match self.receiver.try_recv() {
            Ok(item) => {
                self.stats.dequeued.fetch_add(1, Ordering::Relaxed);
                self.stats.current_size.fetch_sub(1, Ordering::Relaxed);
                Some(item)
            }
            Err(_) => None,
        }
    }
    
    /// è·å–é˜Ÿåˆ—é•¿åº¦
    pub fn len(&self) -> usize {
        self.stats.current_size.load(Ordering::Relaxed)
    }
    
    /// æ˜¯å¦ä¸ºç©º
    pub fn is_empty(&self) -> bool {
        self.len() == 0
    }
    
    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn stats(&self) -> &QueueStats {
        &self.stats
    }
}

/// é«˜æ€§èƒ½åŸå­è®¡æ•°å™¨ - æ›¿ä»£RwLock<usize>
pub struct LockFreeCounter {
    value: AtomicUsize,
    stats: Arc<CounterStats>,
}

/// è®¡æ•°å™¨ç»Ÿè®¡
#[derive(Debug)]
pub struct CounterStats {
    pub increments: AtomicU64,
    pub decrements: AtomicU64,
    pub reads: AtomicU64,
}

impl LockFreeCounter {
    /// åˆ›å»ºæ–°çš„æ— é”è®¡æ•°å™¨
    pub fn new(initial: usize) -> Self {
        Self {
            value: AtomicUsize::new(initial),
            stats: Arc::new(CounterStats {
                increments: AtomicU64::new(0),
                decrements: AtomicU64::new(0),
                reads: AtomicU64::new(0),
            }),
        }
    }
    
    /// åŸå­é€’å¢
    pub fn increment(&self) -> usize {
        self.stats.increments.fetch_add(1, Ordering::Relaxed);
        self.value.fetch_add(1, Ordering::Relaxed) + 1
    }
    
    /// åŸå­é€’å‡
    pub fn decrement(&self) -> usize {
        self.stats.decrements.fetch_add(1, Ordering::Relaxed);
        self.value.fetch_sub(1, Ordering::Relaxed).saturating_sub(1)
    }
    
    /// åŸå­è¯»å–
    pub fn get(&self) -> usize {
        self.stats.reads.fetch_add(1, Ordering::Relaxed);
        self.value.load(Ordering::Relaxed)
    }
    
    /// åŸå­è®¾ç½®
    pub fn set(&self, value: usize) {
        self.value.store(value, Ordering::Relaxed);
    }
    
    /// åŸå­äº¤æ¢
    pub fn swap(&self, value: usize) -> usize {
        self.value.swap(value, Ordering::Relaxed)
    }
    
    /// è·å–ç»Ÿè®¡ä¿¡æ¯
    pub fn stats(&self) -> &CounterStats {
        &self.stats
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use std::sync::Arc;
    use std::thread;
    use std::time::Duration;

    #[test]
    fn test_lockfree_hashmap_basic() {
        let map = LockFreeHashMap::new();
        
        // æµ‹è¯•æ’å…¥
        assert!(map.insert("key1".to_string(), "value1".to_string()).is_ok());
        assert_eq!(map.get(&"key1".to_string()), Some("value1".to_string()));
        
        // æµ‹è¯•æ›´æ–°
        assert!(map.insert("key1".to_string(), "value2".to_string()).is_ok());
        assert_eq!(map.get(&"key1".to_string()), Some("value2".to_string()));
        
        // æµ‹è¯•åˆ é™¤
        assert!(map.remove(&"key1".to_string()).is_ok());
        assert_eq!(map.get(&"key1".to_string()), None);
    }
    
    #[test]
    fn test_lockfree_hashmap_concurrent() {
        let map = Arc::new(LockFreeHashMap::new());
        let mut handles = vec![];
        
        // å¹¶å‘å†™å…¥
        for i in 0..10 {
            let map_clone = Arc::clone(&map);
            let handle = thread::spawn(move || {
                for j in 0..100 {
                    let key = format!("key_{}", i * 100 + j);
                    let value = format!("value_{}", i * 100 + j);
                    map_clone.insert(key, value).unwrap();
                }
            });
            handles.push(handle);
        }
        
        // å¹¶å‘è¯»å–
        for i in 0..5 {
            let map_clone = Arc::clone(&map);
            let handle = thread::spawn(move || {
                for _ in 0..1000 {
                    let key = format!("key_{}", i);
                    let _value = map_clone.get(&key);
                }
            });
            handles.push(handle);
        }
        
        for handle in handles {
            handle.join().unwrap();
        }
        
        // éªŒè¯ç»“æœ
        assert_eq!(map.len(), 1000);
        let stats = map.stats();
        println!("CASæˆåŠŸç‡: {:.2}%", stats.cas_success_rate() * 100.0);
    }
    
    #[test]
    fn test_lockfree_queue() {
        let queue = LockFreeQueue::new();
        
        // æµ‹è¯•åŸºæœ¬æ“ä½œ
        assert!(queue.push(1).is_ok());
        assert!(queue.push(2).is_ok());
        assert_eq!(queue.len(), 2);
        
        assert_eq!(queue.pop(), Some(1));
        assert_eq!(queue.pop(), Some(2));
        assert_eq!(queue.pop(), None);
        assert!(queue.is_empty());
    }
    
    #[test]
    fn test_lockfree_counter() {
        let counter = LockFreeCounter::new(0);
        
        assert_eq!(counter.increment(), 1);
        assert_eq!(counter.increment(), 2);
        assert_eq!(counter.get(), 2);
        assert_eq!(counter.decrement(), 1);
        assert_eq!(counter.get(), 1);
    }
} 