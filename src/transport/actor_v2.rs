/// Phase 3.2.2: åŒç®¡é“Actorå¤„ç†ä¼˜åŒ–
/// 
/// æ ¸å¿ƒä¼˜åŒ–ï¼š
/// 1. æ•°æ®ç®¡é“ä¸å‘½ä»¤ç®¡é“åˆ†ç¦»
/// 2. æ‰¹é‡æ•°æ®å¤„ç†
/// 3. ä¸“é—¨åŒ–å¤„ç†å™¨
/// 4. Flumeé«˜æ€§èƒ½é€šä¿¡

use std::sync::atomic::{AtomicU64, AtomicUsize, Ordering};
use std::sync::Arc;
use std::time::{Duration, Instant};
use flume::{Sender as FlumeSender, Receiver as FlumeReceiver};
use tokio::task::JoinHandle;
use crate::{
    error::TransportError,
    packet::Packet,
    SessionId,
    command::{ConnectionInfo, ProtocolType, ConnectionState},
};
use super::protocol_adapter_v2::{FlumePoweredProtocolAdapter, ProtocolEvent};

/// Actorå‘½ä»¤ç±»å‹
#[derive(Debug, Clone)]
pub enum ActorCommand {
    ProcessData(Packet),          // å¤„ç†æ•°æ®åŒ…
    SendPacket(Packet),           // å‘é€æ•°æ®åŒ…
    UpdateSession(SessionId),     // æ›´æ–°ä¼šè¯
    GetStats,                     // è·å–ç»Ÿè®¡
    Shutdown,                     // å…³é—­Actor
    HealthCheck,                  // å¥åº·æ£€æŸ¥
}

/// Actoräº‹ä»¶ç±»å‹
#[derive(Debug, Clone)]  
pub enum ActorEvent {
    DataProcessed(usize),         // æ•°æ®å·²å¤„ç†ï¼Œå‚æ•°ä¸ºåŒ…æ•°é‡
    BatchCompleted(usize),        // æ‰¹æ¬¡å®Œæˆï¼Œå‚æ•°ä¸ºæ‰¹æ¬¡å¤§å°
    StatsReport(ActorStats),      // ç»Ÿè®¡æŠ¥å‘Š
    Error(String),                // é”™è¯¯äº‹ä»¶
    Shutdown,                     // å…³é—­äº‹ä»¶
}

/// Actorç»Ÿè®¡
#[derive(Debug, Clone)]
pub struct ActorStats {
    pub data_packets_processed: u64,
    pub commands_processed: u64,
    pub total_batches: u64,
    pub average_batch_size: f64,
    pub processing_latency_ns: u64,
    pub uptime_seconds: u64,
    pub error_count: u64,
}

/// LockFree Actorç»Ÿè®¡
#[derive(Debug)]
pub struct LockFreeActorStats {
    // æ•°æ®å¤„ç†ç»Ÿè®¡
    pub data_packets_processed: AtomicU64,
    pub data_bytes_processed: AtomicU64,
    pub batch_operations: AtomicU64,
    pub total_batch_size: AtomicU64,
    pub max_batch_size: AtomicUsize,
    
    // å‘½ä»¤å¤„ç†ç»Ÿè®¡
    pub commands_processed: AtomicU64,
    pub command_latency_ns: AtomicU64,
    
    // æ€§èƒ½ç»Ÿè®¡
    pub total_processing_time_ns: AtomicU64,
    pub operation_count: AtomicU64,
    pub error_count: AtomicU64,
    
    // å¯åŠ¨æ—¶é—´
    pub start_time: Instant,
}

impl LockFreeActorStats {
    pub fn new() -> Self {
        Self {
            data_packets_processed: AtomicU64::new(0),
            data_bytes_processed: AtomicU64::new(0),
            batch_operations: AtomicU64::new(0),
            total_batch_size: AtomicU64::new(0),
            max_batch_size: AtomicUsize::new(0),
            commands_processed: AtomicU64::new(0),
            command_latency_ns: AtomicU64::new(0),
            total_processing_time_ns: AtomicU64::new(0),
            operation_count: AtomicU64::new(0),
            error_count: AtomicU64::new(0),
            start_time: Instant::now(),
        }
    }
    
    pub fn record_data_batch(&self, batch_size: usize, total_bytes: usize) {
        self.data_packets_processed.fetch_add(batch_size as u64, Ordering::Relaxed);
        self.data_bytes_processed.fetch_add(total_bytes as u64, Ordering::Relaxed);
        self.batch_operations.fetch_add(1, Ordering::Relaxed);
        self.total_batch_size.fetch_add(batch_size as u64, Ordering::Relaxed);
        self.max_batch_size.fetch_max(batch_size, Ordering::Relaxed);
    }
    
    pub fn record_command(&self, latency_ns: u64) {
        self.commands_processed.fetch_add(1, Ordering::Relaxed);
        self.command_latency_ns.fetch_add(latency_ns, Ordering::Relaxed);
    }
    
    pub fn record_processing_time(&self, processing_time_ns: u64) {
        self.total_processing_time_ns.fetch_add(processing_time_ns, Ordering::Relaxed);
        self.operation_count.fetch_add(1, Ordering::Relaxed);
    }
    
    pub fn record_error(&self) {
        self.error_count.fetch_add(1, Ordering::Relaxed);
    }
    
    pub fn snapshot(&self) -> ActorStats {
        let batch_ops = self.batch_operations.load(Ordering::Relaxed);
        let total_batch_size = self.total_batch_size.load(Ordering::Relaxed);
        
        ActorStats {
            data_packets_processed: self.data_packets_processed.load(Ordering::Relaxed),
            commands_processed: self.commands_processed.load(Ordering::Relaxed),
            total_batches: batch_ops,
            average_batch_size: if batch_ops > 0 {
                total_batch_size as f64 / batch_ops as f64
            } else {
                0.0
            },
            processing_latency_ns: {
                let ops = self.operation_count.load(Ordering::Relaxed);
                if ops > 0 {
                    self.total_processing_time_ns.load(Ordering::Relaxed) / ops
                } else {
                    0
                }
            },
            uptime_seconds: self.start_time.elapsed().as_secs(),
            error_count: self.error_count.load(Ordering::Relaxed),
        }
    }
}

/// Phase 3.2.2 ä¼˜åŒ–çš„åŒç®¡é“Actor
pub struct OptimizedActor {
    // æ•°æ®ç®¡é“ï¼ˆé«˜é¢‘ï¼‰
    data_tx: FlumeSender<Packet>,
    data_rx: FlumeReceiver<Packet>,
    
    // å‘½ä»¤ç®¡é“ï¼ˆä½é¢‘ï¼‰
    command_tx: FlumeSender<ActorCommand>,
    command_rx: FlumeReceiver<ActorCommand>,
    
    // äº‹ä»¶å¹¿æ’­
    event_tx: FlumeSender<ActorEvent>,
    
    // åè®®é€‚é…å™¨
    protocol_adapter: FlumePoweredProtocolAdapter,
    
    // LockFreeç»Ÿè®¡
    stats: Arc<LockFreeActorStats>,
    
    // ä¼šè¯ä¿¡æ¯
    session_id: SessionId,
    
    // æ‰¹é‡å¤„ç†é…ç½®
    max_batch_size: usize,
    batch_timeout_ms: u64,
}

impl OptimizedActor {
    /// åˆ›å»ºæ–°çš„ä¼˜åŒ–Actor
    pub fn new(
        session_id: SessionId,
        protocol_adapter: FlumePoweredProtocolAdapter,
        max_batch_size: usize,
        batch_timeout_ms: u64,
    ) -> (Self, FlumeReceiver<ActorEvent>, FlumeSender<Packet>, FlumeSender<ActorCommand>) {
        let (data_tx, data_rx) = flume::unbounded();
        let (command_tx, command_rx) = flume::unbounded();
        let (event_tx, event_rx) = flume::unbounded();
        
        let actor = Self {
            data_tx: data_tx.clone(),
            data_rx,
            command_tx: command_tx.clone(),
            command_rx,
            event_tx,
            protocol_adapter,
            stats: Arc::new(LockFreeActorStats::new()),
            session_id,
            max_batch_size,
            batch_timeout_ms,
        };
        
        (actor, event_rx, data_tx, command_tx)
    }
    
    /// æ ¸å¿ƒä¼˜åŒ–ï¼šåŒç®¡é“è¿è¡Œå¾ªç¯
    pub async fn run_flume_pipeline(mut self) -> Result<(), TransportError> {
        println!("ğŸš€ å¯åŠ¨ä¼˜åŒ–ActoråŒç®¡é“å¤„ç† (ä¼šè¯: {})", self.session_id);
        
        // å¯åŠ¨æ•°æ®å¤„ç†ç®¡é“
        let data_processor = {
            let data_rx = self.data_rx.clone();
            let event_tx = self.event_tx.clone();
            let stats = self.stats.clone();
            let max_batch = self.max_batch_size;
            
            tokio::spawn(async move {
                Self::run_data_pipeline(data_rx, event_tx, stats, max_batch).await
            })
        };
        
        // å¯åŠ¨å‘½ä»¤å¤„ç†ç®¡é“
        let command_processor = {
            let command_rx = self.command_rx.clone();
            let event_tx = self.event_tx.clone();
            let stats = self.stats.clone();
            
            tokio::spawn(async move {
                Self::run_command_pipeline(command_rx, event_tx, stats).await
            })
        };
        
        // ç­‰å¾…ä»»ä¸€ç®¡é“å®Œæˆ
        tokio::select! {
            result = data_processor => {
                println!("ğŸ“¦ æ•°æ®å¤„ç†ç®¡é“å®Œæˆ: {:?}", result);
            },
            result = command_processor => {
                println!("ğŸ›ï¸ å‘½ä»¤å¤„ç†ç®¡é“å®Œæˆ: {:?}", result);
            },
        }
        
        // å‘é€å…³é—­äº‹ä»¶
        let _ = self.event_tx.try_send(ActorEvent::Shutdown);
        
        Ok(())
    }
    
    /// æ ¸å¿ƒä¼˜åŒ–ï¼šä¸“é—¨çš„æ•°æ®å¤„ç†ç®¡é“
    async fn run_data_pipeline(
        data_rx: FlumeReceiver<Packet>,
        event_tx: FlumeSender<ActorEvent>,
        stats: Arc<LockFreeActorStats>,
        max_batch_size: usize,
    ) {
        println!("ğŸ“¦ å¯åŠ¨æ•°æ®å¤„ç†ç®¡é“ (æœ€å¤§æ‰¹æ¬¡: {})", max_batch_size);
        
        while let Ok(first_packet) = data_rx.recv_async().await {
            let start_time = Instant::now();
            let mut batch = vec![first_packet];
            
            // ğŸš€ å…³é”®ä¼˜åŒ–ï¼šæ‰¹é‡æ”¶é›†æ•°æ®åŒ…
            while batch.len() < max_batch_size {
                match data_rx.try_recv() {
                    Ok(packet) => batch.push(packet),
                    Err(_) => break,
                }
            }
            
            // æ‰¹é‡å¤„ç†æ•°æ®åŒ…
            let batch_size = batch.len();
            let total_bytes: usize = batch.iter().map(|p| p.payload.len()).sum();
            
            // æ¨¡æ‹Ÿæ•°æ®å¤„ç†ï¼ˆå®é™…å®ç°ä¼šè°ƒç”¨å…·ä½“çš„å¤„ç†é€»è¾‘ï¼‰
            Self::process_packet_batch(&batch).await;
            
            // æ›´æ–°ç»Ÿè®¡
            stats.record_data_batch(batch_size, total_bytes);
            let processing_time = start_time.elapsed().as_nanos() as u64;
            stats.record_processing_time(processing_time);
            
            // å‘é€äº‹ä»¶
            let _ = event_tx.try_send(ActorEvent::BatchCompleted(batch_size));
            
            if batch_size > 1 {
                println!("ğŸ“¦ æ‰¹é‡å¤„ç† {} ä¸ªæ•°æ®åŒ… ({} bytes, {:.2}Î¼s)", 
                        batch_size, total_bytes, processing_time as f64 / 1000.0);
            }
        }
        
        println!("ğŸ“¦ æ•°æ®å¤„ç†ç®¡é“é€€å‡º");
    }
    
    /// ä¸“é—¨çš„å‘½ä»¤å¤„ç†ç®¡é“
    async fn run_command_pipeline(
        command_rx: FlumeReceiver<ActorCommand>,
        event_tx: FlumeSender<ActorEvent>,
        stats: Arc<LockFreeActorStats>,
    ) {
        println!("ğŸ›ï¸ å¯åŠ¨å‘½ä»¤å¤„ç†ç®¡é“");
        
        while let Ok(command) = command_rx.recv_async().await {
            let start_time = Instant::now();
            
            match command {
                ActorCommand::ProcessData(packet) => {
                    // å•ä¸ªæ•°æ®åŒ…å¤„ç†
                    Self::process_single_packet(&packet).await;
                },
                ActorCommand::SendPacket(packet) => {
                    // å‘é€æ•°æ®åŒ…
                    println!("ğŸ“¤ å‘é€æ•°æ®åŒ…: {} bytes", packet.payload.len());
                },
                ActorCommand::UpdateSession(session_id) => {
                    println!("ğŸ”„ æ›´æ–°ä¼šè¯: {}", session_id);
                },
                ActorCommand::GetStats => {
                    let stats_snapshot = stats.snapshot();
                    let _ = event_tx.try_send(ActorEvent::StatsReport(stats_snapshot));
                },
                ActorCommand::Shutdown => {
                    println!("ğŸ›‘ æ”¶åˆ°å…³é—­å‘½ä»¤");
                    break;
                },
                ActorCommand::HealthCheck => {
                    println!("ğŸ’“ å¥åº·æ£€æŸ¥é€šè¿‡");
                },
            }
            
            let latency = start_time.elapsed().as_nanos() as u64;
            stats.record_command(latency);
        }
        
        println!("ğŸ›ï¸ å‘½ä»¤å¤„ç†ç®¡é“é€€å‡º");
    }
    
    /// æ‰¹é‡æ•°æ®åŒ…å¤„ç†
    async fn process_packet_batch(batch: &[Packet]) {
        // æ¨¡æ‹Ÿæ‰¹é‡å¤„ç†é€»è¾‘
        for (i, packet) in batch.iter().enumerate() {
            if i % 10 == 0 {
                tokio::task::yield_now().await;
            }
            // å®é™…å¤„ç†é€»è¾‘ä¼šåœ¨è¿™é‡Œ
        }
    }
    
    /// å•ä¸ªæ•°æ®åŒ…å¤„ç†
    async fn process_single_packet(packet: &Packet) {
        // æ¨¡æ‹Ÿå•åŒ…å¤„ç†
        tokio::task::yield_now().await;
    }
    
    /// è·å–æ€§èƒ½ç»Ÿè®¡
    pub fn get_stats(&self) -> ActorStats {
        self.stats.snapshot()
    }
    
    /// å‘é€æ•°æ®åŒ…åˆ°æ•°æ®ç®¡é“
    pub fn send_data(&self, packet: Packet) -> Result<(), TransportError> {
        self.data_tx.try_send(packet)
            .map_err(|_| TransportError::connection_error("Channel full: actor_data", false))
    }
    
    /// å‘é€å‘½ä»¤åˆ°å‘½ä»¤ç®¡é“
    pub fn send_command(&self, command: ActorCommand) -> Result<(), TransportError> {
        self.command_tx.try_send(command)
            .map_err(|_| TransportError::connection_error("Channel full: actor_command", false))
    }
}

// æ³¨æ„ï¼šFlumePoweredProtocolAdapterä¸æ”¯æŒCloneï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ArcåŒ…è£…

/// Actorç®¡ç†å™¨
pub struct ActorManager {
    actors: Vec<JoinHandle<Result<(), TransportError>>>,
    event_receivers: Vec<FlumeReceiver<ActorEvent>>,
    pub data_senders: Vec<FlumeSender<Packet>>,
    command_senders: Vec<FlumeSender<ActorCommand>>,
}

impl ActorManager {
    pub fn new() -> Self {
        Self {
            actors: Vec::new(),
            event_receivers: Vec::new(),
            data_senders: Vec::new(),
            command_senders: Vec::new(),
        }
    }
    
    /// å¯åŠ¨å¤šä¸ªActor
    pub async fn spawn_actors(
        &mut self,
        count: usize,
        max_batch_size: usize,
        batch_timeout_ms: u64,
    ) -> Result<(), TransportError> {
        for i in 0..count {
            let connection_info = ConnectionInfo {
                session_id: crate::SessionId::new(i as u64 + 1),
                local_addr: format!("127.0.0.1:{}", 8080 + i).parse().unwrap(),
                peer_addr: format!("127.0.0.1:{}", 9080 + i).parse().unwrap(),
                protocol: ProtocolType::Tcp,
                state: ConnectionState::Connected,
                established_at: std::time::SystemTime::now(),
                closed_at: None,
                last_activity: std::time::SystemTime::now(),
                packets_sent: 0,
                packets_received: 0,
                bytes_sent: 0,
                bytes_received: 0,
            };
            
            let (protocol_adapter, _protocol_events) = 
                super::protocol_adapter_v2::FlumePoweredProtocolAdapter::new(crate::SessionId::new(i as u64 + 1), connection_info);
            
            let (actor, event_rx, data_tx, command_tx) = OptimizedActor::new(
                crate::SessionId::new(i as u64 + 1),
                protocol_adapter,
                max_batch_size,
                batch_timeout_ms,
            );
            
            let handle = tokio::spawn(actor.run_flume_pipeline());
            
            self.actors.push(handle);
            self.event_receivers.push(event_rx);
            self.data_senders.push(data_tx);
            self.command_senders.push(command_tx);
        }
        
        println!("ğŸš€ å·²å¯åŠ¨ {} ä¸ªä¼˜åŒ–Actor", count);
        Ok(())
    }
    
    /// å¹¿æ’­æ•°æ®åŒ…åˆ°æ‰€æœ‰Actor
    pub fn broadcast_data(&self, packet: Packet) -> usize {
        let mut success_count = 0;
        for sender in &self.data_senders {
            if sender.try_send(packet.clone()).is_ok() {
                success_count += 1;
            }
        }
        success_count
    }
    
    /// å¹¿æ’­å‘½ä»¤åˆ°æ‰€æœ‰Actor
    pub fn broadcast_command(&self, command: ActorCommand) -> usize {
        let mut success_count = 0;
        for sender in &self.command_senders {
            if sender.try_send(command.clone()).is_ok() {
                success_count += 1;
            }
        }
        success_count
    }
    
    /// ç­‰å¾…æ‰€æœ‰Actorå®Œæˆ
    pub async fn wait_all(&mut self) -> Vec<Result<Result<(), TransportError>, tokio::task::JoinError>> {
        let handles = std::mem::take(&mut self.actors);
        futures::future::join_all(handles).await
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::transport::protocol_adapter_v2::create_test_packet;
    
    #[tokio::test]
    async fn test_optimized_actor_basic() {
        let connection_info = ConnectionInfo {
            session_id: crate::SessionId::new(1),
            local_addr: "127.0.0.1:8080".parse().unwrap(),
            peer_addr: "127.0.0.1:8081".parse().unwrap(),
            protocol: ProtocolType::Tcp,
            state: ConnectionState::Connected,
            established_at: std::time::SystemTime::now(),
            closed_at: None,
            last_activity: std::time::SystemTime::now(),
            packets_sent: 0,
            packets_received: 0,
            bytes_sent: 0,
            bytes_received: 0,
        };
        
        let (protocol_adapter, _) = super::super::protocol_adapter_v2::FlumePoweredProtocolAdapter::new(1, connection_info);
        let (actor, _event_rx, data_tx, command_tx) = OptimizedActor::new(crate::SessionId::new(1), protocol_adapter, 32, 100);
        
        // æµ‹è¯•å‘é€æ•°æ®
        let packet = create_test_packet(1, 1024);
        assert!(data_tx.try_send(packet).is_ok());
        
        // æµ‹è¯•å‘é€å‘½ä»¤
        assert!(command_tx.try_send(ActorCommand::HealthCheck).is_ok());
        
        let stats = actor.get_stats();
        assert_eq!(stats.error_count, 0);
    }
    
    #[tokio::test]
    async fn test_actor_manager() {
        let mut manager = ActorManager::new();
        
        // å¯åŠ¨å¤šä¸ªActor
        assert!(manager.spawn_actors(3, 16, 50).await.is_ok());
        
        // å¹¿æ’­æ•°æ®
        let packet = create_test_packet(1, 512);
        let sent_count = manager.broadcast_data(packet);
        assert_eq!(sent_count, 3);
        
        // å¹¿æ’­å‘½ä»¤
        let sent_count = manager.broadcast_command(ActorCommand::HealthCheck);
        assert_eq!(sent_count, 3);
        
        // ç­‰å¾…ä¸€å°æ®µæ—¶é—´è®©å¤„ç†å®Œæˆ
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        // å‘é€å…³é—­å‘½ä»¤
        let _sent_count = manager.broadcast_command(ActorCommand::Shutdown);
        
        // ç­‰å¾…æ‰€æœ‰Actorå®Œæˆ
        let results = manager.wait_all().await;
        assert_eq!(results.len(), 3);
    }
} 