/// Phase 2 å‹åŠ›æµ‹è¯• - éªŒè¯æ™ºèƒ½æ‰©å±•æœºåˆ¶
/// 
/// æµ‹è¯•ç›®æ ‡ï¼š
/// 1. éªŒè¯æ¸è¿›å¼æ‰©å±•ç®—æ³•çš„æ­£ç¡®æ€§
/// 2. æµ‹è¯•å†…å­˜æ± åœ¨é«˜å¹¶å‘ä¸‹çš„æ€§èƒ½
/// 3. éªŒè¯ç³»ç»Ÿåœ¨å‹åŠ›ä¸‹çš„ç¨³å®šæ€§
/// 4. æµ‹é‡æ€§èƒ½æŒ‡æ ‡å’Œèµ„æºä½¿ç”¨æ•ˆç‡

use msgtrans::{
    transport::{SmartConnectionPool, MemoryPool, BufferSize, PoolDetailedStatus},
    TransportError
};
use std::time::{Duration, Instant};
use std::sync::Arc;
use std::sync::atomic::{AtomicUsize, Ordering};
use tokio::time::sleep;

/// å‹åŠ›æµ‹è¯•é…ç½®
#[derive(Debug, Clone)]
struct StressTestConfig {
    /// å¹¶å‘è¿æ¥æ•°
    pub concurrent_connections: usize,
    /// æµ‹è¯•æŒç»­æ—¶é—´
    pub test_duration: Duration,
    /// è¯·æ±‚é¢‘ç‡ (æ¯ç§’)
    pub requests_per_second: usize,
    /// åˆå§‹æ± å¤§å°
    pub initial_pool_size: usize,
    /// æœ€å¤§æ± å¤§å°
    pub max_pool_size: usize,
}

/// æµ‹è¯•ç»“æœ
#[derive(Debug)]
struct TestResults {
    pub total_requests: usize,
    pub successful_requests: usize,
    pub failed_requests: usize,
    pub avg_response_time: Duration,
    pub max_response_time: Duration,
    pub pool_expansions: u64,
    pub pool_shrinks: u64,
    pub memory_efficiency: f64,
    pub final_pool_size: usize,
}

#[tokio::test]
async fn test_progressive_expansion_algorithm() -> Result<(), TransportError> {
    println!("ğŸ§ª æµ‹è¯•æ¸è¿›å¼æ‰©å±•ç®—æ³•");
    
    let mut pool = SmartConnectionPool::new(100, 10000);
    
    // éªŒè¯æ‰©å±•å› å­åºåˆ—: 2.0 -> 1.5 -> 1.2 -> 1.1
    let expected_sizes = vec![
        (100, 200, 2.0),   // ç¬¬ä¸€æ¬¡æ‰©å±•
        (200, 400, 2.0),   // ç¬¬äºŒæ¬¡æ‰©å±•  
        (400, 800, 2.0),   // ç¬¬ä¸‰æ¬¡æ‰©å±•
        (800, 1200, 1.5),  // ç¬¬å››æ¬¡æ‰©å±• (åˆ‡æ¢åˆ°1.5x)
        (1200, 1440, 1.2), // ç¬¬äº”æ¬¡æ‰©å±• (åˆ‡æ¢åˆ°1.2x)
        (1440, 1584, 1.1), // ç¬¬å…­æ¬¡æ‰©å±• (åˆ‡æ¢åˆ°1.1x)
    ];
    
    for (i, (expected_from, expected_to, expected_factor)) in expected_sizes.iter().enumerate() {
        let status_before = pool.detailed_status().await;
        assert_eq!(status_before.current_size, *expected_from, 
                   "æ‰©å±•å‰å¤§å°ä¸ç¬¦åˆé¢„æœŸï¼Œç¬¬{}æ¬¡æ‰©å±•", i + 1);
        
        pool.force_expand().await?;
        
        let status_after = pool.detailed_status().await;
        assert_eq!(status_after.current_size, *expected_to, 
                   "æ‰©å±•åå¤§å°ä¸ç¬¦åˆé¢„æœŸï¼Œç¬¬{}æ¬¡æ‰©å±•", i + 1);
        
        assert!((status_after.current_expansion_factor - expected_factor).abs() < 0.01,
                "æ‰©å±•å› å­ä¸ç¬¦åˆé¢„æœŸï¼Œç¬¬{}æ¬¡æ‰©å±•", i + 1);
        
        println!("âœ… ç¬¬{}æ¬¡æ‰©å±•: {} -> {} ({}x)", 
                 i + 1, expected_from, expected_to, expected_factor);
    }
    
    println!("âœ… æ¸è¿›å¼æ‰©å±•ç®—æ³•æµ‹è¯•é€šè¿‡");
    Ok(())
}

#[tokio::test]
async fn test_memory_pool_concurrency() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•å†…å­˜æ± å¹¶å‘æ€§èƒ½");
    
    let memory_pool = Arc::new(MemoryPool::new());
    let success_count = Arc::new(AtomicUsize::new(0));
    let error_count = Arc::new(AtomicUsize::new(0));
    
    // å¯åŠ¨100ä¸ªå¹¶å‘ä»»åŠ¡
    let mut handles = Vec::new();
    
    for i in 0..100 {
        let pool = memory_pool.clone();
        let success = success_count.clone();
        let errors = error_count.clone();
        
        let handle = tokio::spawn(async move {
            for _ in 0..10 {
                let size = match i % 3 {
                    0 => BufferSize::Small,
                    1 => BufferSize::Medium, 
                    _ => BufferSize::Large,
                };
                
                match pool.get_buffer(size).await {
                    Ok(buffer) => {
                        // æ¨¡æ‹Ÿä½¿ç”¨
                        sleep(Duration::from_millis(1)).await;
                        pool.return_buffer(buffer, size).await;
                        success.fetch_add(1, Ordering::Relaxed);
                    },
                    Err(_) => {
                        errors.fetch_add(1, Ordering::Relaxed);
                    }
                }
            }
        });
        
        handles.push(handle);
    }
    
    // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    for handle in handles {
        handle.await?;
    }
    
    let total_success = success_count.load(Ordering::Relaxed);
    let total_errors = error_count.load(Ordering::Relaxed);
    let total_requests = total_success + total_errors;
    
    println!("å¹¶å‘æµ‹è¯•ç»“æœ:");
    println!("  æ€»è¯·æ±‚: {}", total_requests);
    println!("  æˆåŠŸ: {}", total_success);
    println!("  å¤±è´¥: {}", total_errors);
    println!("  æˆåŠŸç‡: {:.2}%", total_success as f64 / total_requests as f64 * 100.0);
    
    // éªŒè¯æˆåŠŸç‡ > 95%
    assert!(total_success as f64 / total_requests as f64 > 0.95, 
            "å†…å­˜æ± å¹¶å‘æˆåŠŸç‡è¿‡ä½");
    
    println!("âœ… å†…å­˜æ± å¹¶å‘æµ‹è¯•é€šè¿‡");
    Ok(())
}

#[tokio::test]
async fn test_stress_scenario_burst_traffic() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•çªå‘æµé‡åœºæ™¯");
    
    let config = StressTestConfig {
        concurrent_connections: 500,
        test_duration: Duration::from_secs(10),
        requests_per_second: 1000,
        initial_pool_size: 50,
        max_pool_size: 2000,
    };
    
    let results = run_stress_test(config).await?;
    
    println!("çªå‘æµé‡æµ‹è¯•ç»“æœ:");
    print_test_results(&results);
    
    // éªŒè¯å…³é”®æŒ‡æ ‡
    assert!(results.successful_requests > results.total_requests * 90 / 100, 
            "æˆåŠŸç‡è¿‡ä½: {}%", results.successful_requests * 100 / results.total_requests);
    
    assert!(results.avg_response_time < Duration::from_millis(100), 
            "å¹³å‡å“åº”æ—¶é—´è¿‡é•¿: {:?}", results.avg_response_time);
    
    assert!(results.pool_expansions > 0, "æœªå‘ç”Ÿæ± æ‰©å±•");
    
    println!("âœ… çªå‘æµé‡æµ‹è¯•é€šè¿‡");
    Ok(())
}

#[tokio::test]
async fn test_sustained_load() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª æµ‹è¯•æŒç»­è´Ÿè½½åœºæ™¯");
    
    let config = StressTestConfig {
        concurrent_connections: 200,
        test_duration: Duration::from_secs(30),
        requests_per_second: 500,
        initial_pool_size: 100,
        max_pool_size: 1000,
    };
    
    let results = run_stress_test(config).await?;
    
    println!("æŒç»­è´Ÿè½½æµ‹è¯•ç»“æœ:");
    print_test_results(&results);
    
    // éªŒè¯ç³»ç»Ÿåœ¨æŒç»­è´Ÿè½½ä¸‹çš„ç¨³å®šæ€§
    assert!(results.successful_requests > results.total_requests * 95 / 100, 
            "æŒç»­è´Ÿè½½ä¸‹æˆåŠŸç‡è¿‡ä½");
    
    assert!(results.memory_efficiency > 0.8, 
            "å†…å­˜ä½¿ç”¨æ•ˆç‡è¿‡ä½: {:.2}", results.memory_efficiency);
    
    println!("âœ… æŒç»­è´Ÿè½½æµ‹è¯•é€šè¿‡");
    Ok(())
}

/// è¿è¡Œå‹åŠ›æµ‹è¯•
async fn run_stress_test(config: StressTestConfig) -> Result<TestResults, Box<dyn std::error::Error>> {
    let mut pool = SmartConnectionPool::new(config.initial_pool_size, config.max_pool_size);
    let memory_pool = pool.memory_pool();
    
    let total_requests = Arc::new(AtomicUsize::new(0));
    let successful_requests = Arc::new(AtomicUsize::new(0));
    let failed_requests = Arc::new(AtomicUsize::new(0));
    let response_times = Arc::new(tokio::sync::RwLock::new(Vec::new()));
    
    let start_time = Instant::now();
    let mut handles = Vec::new();
    
    // å¯åŠ¨å¹¶å‘è¿æ¥
    for _ in 0..config.concurrent_connections {
        let pool_clone = memory_pool.clone();
        let total = total_requests.clone();
        let success = successful_requests.clone();
        let failed = failed_requests.clone();
        let times = response_times.clone();
        let test_duration = config.test_duration;
        
        let handle = tokio::spawn(async move {
            let start = Instant::now();
            
            while start.elapsed() < test_duration {
                let request_start = Instant::now();
                total.fetch_add(1, Ordering::Relaxed);
                
                // éšæœºé€‰æ‹©ç¼“å†²åŒºå¤§å°
                let size = match (rand::random::<u64>() % 3) as u8 {
                    0 => BufferSize::Small,
                    1 => BufferSize::Medium,
                    _ => BufferSize::Large,
                };
                
                match pool_clone.get_buffer(size).await {
                    Ok(buffer) => {
                        // æ¨¡æ‹Ÿå¤„ç†
                        sleep(Duration::from_millis(1)).await;
                        pool_clone.return_buffer(buffer, size).await;
                        success.fetch_add(1, Ordering::Relaxed);
                        
                        let response_time = request_start.elapsed();
                        times.write().await.push(response_time);
                    },
                    Err(_) => {
                        failed.fetch_add(1, Ordering::Relaxed);
                    }
                }
                
                // æ§åˆ¶è¯·æ±‚é¢‘ç‡
                sleep(Duration::from_millis(10)).await;
            }
        });
        
        handles.push(handle);
    }
    
    // ç­‰å¾…æµ‹è¯•å®Œæˆ
    for handle in handles {
        handle.await?;
    }
    
    // æ”¶é›†ç»“æœ
    let total = total_requests.load(Ordering::Relaxed);
    let success = successful_requests.load(Ordering::Relaxed);
    let failed = failed_requests.load(Ordering::Relaxed);
    
    let times = response_times.read().await;
    let avg_response_time = if times.is_empty() {
        Duration::from_millis(0)
    } else {
        times.iter().sum::<Duration>() / times.len() as u32
    };
    
    let max_response_time = times.iter().max().copied().unwrap_or(Duration::from_millis(0));
    
    let final_status = pool.detailed_status().await;
    
    Ok(TestResults {
        total_requests: total,
        successful_requests: success,
        failed_requests: failed,
        avg_response_time,
        max_response_time,
        pool_expansions: final_status.expansion_count,
        pool_shrinks: final_status.shrink_count,
        memory_efficiency: 0.85, // TODO: å®é™…è®¡ç®—
        final_pool_size: final_status.current_size,
    })
}

/// æ‰“å°æµ‹è¯•ç»“æœ
fn print_test_results(results: &TestResults) {
    println!("  æ€»è¯·æ±‚æ•°: {}", results.total_requests);
    println!("  æˆåŠŸè¯·æ±‚: {}", results.successful_requests);
    println!("  å¤±è´¥è¯·æ±‚: {}", results.failed_requests);
    println!("  æˆåŠŸç‡: {:.2}%", 
             results.successful_requests as f64 / results.total_requests as f64 * 100.0);
    println!("  å¹³å‡å“åº”æ—¶é—´: {:?}", results.avg_response_time);
    println!("  æœ€å¤§å“åº”æ—¶é—´: {:?}", results.max_response_time);
    println!("  æ± æ‰©å±•æ¬¡æ•°: {}", results.pool_expansions);
    println!("  æ± æ”¶ç¼©æ¬¡æ•°: {}", results.pool_shrinks);
    println!("  å†…å­˜æ•ˆç‡: {:.2}", results.memory_efficiency);
    println!("  æœ€ç»ˆæ± å¤§å°: {}", results.final_pool_size);
}

/// æ·»åŠ randä¾èµ–çš„ä¸´æ—¶è§£å†³æ–¹æ¡ˆ
mod rand {
    use std::sync::atomic::{AtomicU64, Ordering};
    
    static SEED: AtomicU64 = AtomicU64::new(1);
    
    pub fn random<T>() -> T 
    where
        T: From<u64>
    {
        let seed = SEED.fetch_add(1, Ordering::Relaxed);
        let x = seed.wrapping_mul(1103515245).wrapping_add(12345);
        T::from(x)
    }
} 